{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2f96eb-5e82-4e2c-8ede-ef374064b411",
   "metadata": {},
   "source": [
    "# PointNet Implementation\n",
    "## for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdff8187-00bf-4333-8af7-4d52f6af7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colors import LogNorm\n",
    "import time as t\n",
    "import scipy.constants as spc\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/russbate/MLPionCollaboration/LCStudies/')\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import deep_set_util as dsu\n",
    "\n",
    "plotpath = '/home/russbate/MLPionCollaboration/LCStudies/segmentation/Plots/October/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab46c04-4874-4560-b826-4f726f2f3a53",
   "metadata": {},
   "source": [
    "## Declare GPUs and Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe0a3c2-5b59-4583-9f3f-bbd00ba8b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 14:49:16.568922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 9672 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:88:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"4\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4493b1f-ca03-481c-8aed-13d5a80bf0d6",
   "metadata": {},
   "source": [
    "## Load Models for PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9859cc-916f-4798-9c31-65fc819d4dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac7f3593-9c8e-4038-b174-073b91b1c31f",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "### X = [Energy, Eta, Phi, rPerp]\n",
    "### Y = [EM Energy, non EM Energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8c13771-b239-4c4b-8cd4-001dddde5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 1078, 4)\n",
      "(2550, 1078, 2)\n",
      "Time to load memory mapped data: 0.31387925148010254 (s)\n"
     ]
    }
   ],
   "source": [
    "t0 = t.time()\n",
    "Xraw = np.load('/data/atlas/rbate/Rho_X_4_files.npy', mmap_mode='r')[:,:,:]\n",
    "Yraw = np.load('/data/atlas/rbate/Rho_Y_4_files.npy', mmap_mode='r')[:,:,:]\n",
    "print(Xraw.shape)\n",
    "print(Yraw.shape)\n",
    "\n",
    "X = np.lib.format.open_memmap('/data/atlas/rbate/XR_notebook.npy',\n",
    "                             mode='w+', dtype=np.float64, shape=(Xraw.shape[0], Xraw.shape[1], Xraw.shape[2]))\n",
    "\n",
    "Y = np.lib.format.open_memmap('/data/atlas/rbate/YR_notebook.npy',\n",
    "                             mode='w+', dtype=np.float64, shape=(Yraw.shape[0], Yraw.shape[1], Yraw.shape[2]))\n",
    "np.copyto(dst=Y, src=Yraw[:,:,:], casting='same_kind', where=True)\n",
    "t1 = t.time()\n",
    "\n",
    "Energy_EM = np.ndarray.copy(Yraw[:,:,0])\n",
    "Energy_nonEM = np.ndarray.copy(Yraw[:,:,1])\n",
    "nz_mask = (Energy_EM + Energy_nonEM) != 0\n",
    "\n",
    "# Make sure that non-zero elements are copied as zeros due to mis-match\n",
    "np.copyto(dst=X[nz_mask,:], src=Xraw[nz_mask,:], casting='same_kind', where=True)\n",
    "X[np.invert(nz_mask),:] = 0\n",
    "\n",
    "print('Time to load memory mapped data: '+str(t1-t0)+' (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39c5f5-0ed3-431e-be7c-7dcb0796e9a6",
   "metadata": {},
   "source": [
    "## Create Categorization Labels\n",
    "Still don't know what to do with the mismatch between truth and reported cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "269049c0-e9b8-4e1d-b0c3-be5e68ae77f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number EM: 389638\n",
      "Number NON-EM: 18871\n",
      "Number MIX: 2340391\n"
     ]
    }
   ],
   "source": [
    "EM = np.full(nz_mask.shape, np.nan)\n",
    "nonEM = np.full(nz_mask.shape, np.nan)\n",
    "target_ratio = np.full((nz_mask.shape), np.nan)\n",
    "\n",
    "EM[nz_mask] = np.ndarray.copy(Yraw[nz_mask,0])\n",
    "nonEM[nz_mask] = np.ndarray.copy(Yraw[nz_mask,1])\n",
    "\n",
    "target_labels = np.full((nz_mask.shape[0],nz_mask.shape[1],3), 0)\n",
    "target_ratio[nz_mask] = EM[nz_mask] / (EM[nz_mask] + nonEM[nz_mask])\n",
    "\n",
    "em_mask = target_ratio > .8\n",
    "nonem_mask = target_ratio < .2\n",
    "mix_mask = np.invert(np.logical_or(em_mask, nonem_mask))\n",
    "\n",
    "target_labels[em_mask,0] = 1\n",
    "target_labels[mix_mask,1] = 1\n",
    "target_labels[nonem_mask,2] = 1\n",
    "\n",
    "print('Number EM: '+str(np.count_nonzero(em_mask)))\n",
    "print('Number NON-EM: '+str(np.count_nonzero(nonem_mask)))\n",
    "print('Number MIX: '+str(np.count_nonzero(mix_mask)))\n",
    "\n",
    "# change the pointer for Y to the target labels\n",
    "Y = target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc08711-bfd8-43bb-96f8-db34edc39693",
   "metadata": {},
   "source": [
    "#### Troubleshooting step:\n",
    " - [x] Make sure that target ratio and inputs have no nan values\n",
    " - [x] make sure that the X array is using the nz_mask so there are no mis-matches\n",
    "   - This seems to be the problem, the mis-matches between values were yielding nans in the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7621abc3-3f82-4d12-a41b-2c2db1a5d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(target_labels == np.nan))\n",
    "print(np.any(X == np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37d3ae-db1f-4d4c-8398-b20435b227e7",
   "metadata": {},
   "source": [
    "## Point Normalization\n",
    " - [x] Convert to x,y,z\n",
    " - [x] Investigate Inputs (Rho_Pre-processing.ipynb)\n",
    " - [ ] Speed up the normalization process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6f8c046-73c7-4dd2-af08-31589f7b782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 1078)\n",
      "(527667, 3)\n",
      "Time to convert to xyz: 56.595319747924805 (s)\n",
      "Time to normalize: 0.15347528457641602 (s)\n",
      "Total time: 56.74879503250122 (s)\n",
      "Target shape: (2550, 1078, 3)\n",
      "Input shape: (2550, 1078, 4)\n"
     ]
    }
   ],
   "source": [
    "print(cell_mask.shape)\n",
    "print(X[nz_mask, :3].shape)\n",
    "\n",
    "t0 = t.time()\n",
    "X[nz_mask, 1:4] = dsu.to_xyz(X[nz_mask, 1:4])\n",
    "\n",
    "t1 = t.time()\n",
    "\n",
    "## ENERGY ##\n",
    "log_E_mask = X[:,:,0] > 0\n",
    "X[log_E_mask,0] = np.log(X[log_E_mask,0])\n",
    "\n",
    "## X ##\n",
    "X[:,:,1] = X[:,:,1]/3000\n",
    "\n",
    "## Y ##\n",
    "X[:,:,2] = X[:,:,2]/1000\n",
    "\n",
    "## Z ##\n",
    "X[:,:,3] = X[:,:,3]/1000\n",
    "t2 = t.time()\n",
    "\n",
    "print('Time to convert to xyz: '+str(t1-t0)+' (s)')\n",
    "print('Time to normalize: '+str(t2-t1)+' (s)')\n",
    "print('Total time: '+str(t2-t0)+' (s)')\n",
    "print('Target shape: '+str(Y.shape))\n",
    "print('Input shape: '+str(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ec8ca-0445-4ede-934e-24b3ff61c696",
   "metadata": {},
   "source": [
    "### More Data Pre-Processing\n",
    "Working on solution for points of varying input, this should be taken care of with the max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15b1f4d9-3d10-465c-a15e-91a41d4f6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = X.shape[1]\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed83db9-d573-426e-a4e4-5ed15faacd22",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0de46847-f7fe-4aea-ac4b-28d645d22000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "674ed788-2f4b-44a3-bb79-f60a2332fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "03941193-a5da-4e5e-b16b-16d9422fca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2,2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2c2d6716-ff09-4c13-b98e-3d310cbda336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "    \n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2,1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "904f9742-c484-4d1d-950e-246fdd4f8e58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"point_net_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 1078, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1078, 32)     160         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1078, 32)     128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1078, 32)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 1078, 64)     2112        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1078, 64)     256         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 1078, 64)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1078, 512)    33280       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1078, 512)    2048        conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 1078, 512)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 512)          0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          131328      global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 256)          1024        dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 256)          0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          32896       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 128)          512         dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 128)          0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 16)           2064        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 4, 4)         0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 1078, 4)      0           input_6[0][0]                    \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1078, 32)     160         dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1078, 32)     128         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1078, 32)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1078, 32)     1056        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 1078, 32)     128         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1078, 32)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1078, 32)     1056        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1078, 32)     128         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1078, 32)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 1078, 64)     2112        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1078, 64)     256         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1078, 64)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 1078, 512)    33280       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1078, 512)    2048        conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1078, 512)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 512)          0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          131328      global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 256)          1024        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 256)          0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          32896       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 128)          512         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 128)          0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1024)         132096      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 32, 32)       0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 1078, 32)     0           activation_91[0][0]              \n",
      "                                                                 reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 1078, 32)     1056        dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 1078, 32)     128         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1078, 32)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 1078, 64)     2112        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 1078, 64)     256         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1078, 64)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 1078, 512)    33280       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 1078, 512)    2048        conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 1078, 512)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 512)          0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 256)          131328      global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 256)          1024        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 256)          0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 128)          32896       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 128)          512         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 128)          0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 3234)         417186      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1078, 3)      0           dense_53[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,165,842\n",
      "Trainable params: 1,159,762\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 4))\n",
    "\n",
    "x = tnet(inputs, 4)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_POINTS*NUM_CLASSES, activation=\"softmax\")(x)\n",
    "resh_out = layers.Reshape((NUM_POINTS, NUM_CLASSES))(outputs)\n",
    "\n",
    "point_net_1 = keras.Model(inputs=inputs, outputs=resh_out, name=\"point_net_1\")\n",
    "point_net_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c687b8d-04e9-45f0-ad95-ffb2e8604983",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e21596d5-272f-42a9-8509-f6b5bb3bb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_loss = keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    "    reduction=\"auto\",\n",
    "    name=\"categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "point_optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "point_net_1.compile(loss=point_loss, optimizer=point_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcfc7b-e86f-43b5-921a-ce8bb08d9ceb",
   "metadata": {},
   "source": [
    "## Set up Datasets and Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "771a3058-39ff-4b04-acc6-8e4d628e937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1785\n",
      "Number of validation samples: 382\n",
      "Number of test samples: 383\n"
     ]
    }
   ],
   "source": [
    "train_num, val_num, test_num = dsu.tvt_num(X, tvt=(70,15,15))\n",
    "print('Number of training samples: '+str(train_num))\n",
    "print('Number of validation samples: '+str(val_num))\n",
    "print('Number of test samples: '+str(test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539885e4-e631-48c1-9773-60f995458ad8",
   "metadata": {},
   "source": [
    "### Using TF DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a566ab47-5297-4a47-8c35-4e75a8cf5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "\n",
    "# example_dataset = dataset.as_numpy_iterator()\n",
    "# element = example_dataset.next()\n",
    "# Xa, Ya = element\n",
    "\n",
    "# dat_tr = dataset.skip(val_num+test_num)\n",
    "# dat_test = dataset.take(test_num+val_num)\n",
    "# dat_val = dat_test.skip(test_num)\n",
    "# dat_test = dataset.take(test_num)\n",
    "\n",
    "# print(dat_tr.cardinality())\n",
    "# print(dat_test.cardinality())\n",
    "# print(dat_val.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ee90e8e1-008a-4a5d-8037-020dfef1796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbatches = int(np.ceil(1785/382))\n",
    "# print(Nbatches)\n",
    "# batch_size=int(np.floor(1785/Nbatches))\n",
    "# print(batch_size)\n",
    "\n",
    "# dat_tr = dat_tr.batch(Nbatches, drop_remainder=True)\n",
    "# dat_val = dat_val.batch(Nbatches, drop_remainder=True)\n",
    "# dat_test = dat_test.batch(Nbatches, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a53f87-b5fd-4f10-9d53-f540c6182d6f",
   "metadata": {},
   "source": [
    "### Using numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cac52480-3c97-4c8e-a05b-a56bb8ab4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.ndarray.copy(X[:train_num,:,:])\n",
    "Y_train = np.ndarray.copy(Y[:train_num,:,:])\n",
    "\n",
    "X_val = np.ndarray.copy(X[train_num:train_num+val_num,:,:])\n",
    "Y_val = np.ndarray.copy(Y[train_num:train_num+val_num,:,:])\n",
    "\n",
    "X_test = np.ndarray.copy(X[train_num+val_num:,:,:])\n",
    "Y_test = np.ndarray.copy(Y[train_num+val_num:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b87cedde-34e0-4936-92a2-3d4023653891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 1078, 3)\n",
      "(1785, 1078, 4)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a257d-f705-44c9-8f61-5dfe82035e39",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f31d1294-cba9-47f4-85fc-5b5bef90fbcc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 15:07:18.575683: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 4.00G (4294967296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.581667: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 3.60G (3865470464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.583286: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 3.24G (3478923264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.584751: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.92G (3131030784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.586752: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.62G (2817927680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.588587: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.36G (2536134912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.589638: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.12G (2282521344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-29 15:07:18.590742: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 1.91G (2054269184 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 6s 267ms/step - loss: 7.1958 - val_loss: 6.4098\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 6.1861 - val_loss: 5.6272\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 4s 248ms/step - loss: 5.5103 - val_loss: 5.0967\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 5s 283ms/step - loss: 5.0528 - val_loss: 4.7349\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 4s 250ms/step - loss: 4.7370 - val_loss: 4.4802\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 4.5120 - val_loss: 4.2953\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 4.3469 - val_loss: 4.1571\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 4.2224 - val_loss: 4.0512\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 4s 250ms/step - loss: 4.1261 - val_loss: 3.9685\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 4.0504 - val_loss: 3.9025\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 3.9898 - val_loss: 3.8492\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 3.9405 - val_loss: 3.8056\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 5s 258ms/step - loss: 3.9000 - val_loss: 3.7694\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 4s 250ms/step - loss: 3.8664 - val_loss: 3.7391\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 5s 268ms/step - loss: 3.8381 - val_loss: 3.7136\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 3.8141 - val_loss: 3.6917\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 3.7936 - val_loss: 3.6730\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 5s 279ms/step - loss: 3.7760 - val_loss: 3.6568\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 5s 274ms/step - loss: 3.7608 - val_loss: 3.6428\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 10s 573ms/step - loss: 3.7475 - val_loss: 3.6305\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 5s 296ms/step - loss: 3.7358 - val_loss: 3.6197\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 5s 263ms/step - loss: 3.7256 - val_loss: 3.6101\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 3.7165 - val_loss: 3.6016\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 5s 279ms/step - loss: 3.7085 - val_loss: 3.5941\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.7013 - val_loss: 3.5873\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 3.6948 - val_loss: 3.5812\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 5s 271ms/step - loss: 3.6890 - val_loss: 3.5758\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 5s 274ms/step - loss: 3.6837 - val_loss: 3.5708\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 5s 273ms/step - loss: 3.6790 - val_loss: 3.5663\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 5s 267ms/step - loss: 3.6747 - val_loss: 3.5622\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 5s 259ms/step - loss: 3.6708 - val_loss: 3.5584\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 3.6672 - val_loss: 3.5550\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 3.6639 - val_loss: 3.5519\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.6609 - val_loss: 3.5490\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 3.6581 - val_loss: 3.5464\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 5s 281ms/step - loss: 3.6555 - val_loss: 3.5439\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.6532 - val_loss: 3.5416\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 5s 271ms/step - loss: 3.6510 - val_loss: 3.5395\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 5s 273ms/step - loss: 3.6490 - val_loss: 3.5376\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 5s 263ms/step - loss: 3.6471 - val_loss: 3.5357\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 5s 267ms/step - loss: 3.6453 - val_loss: 3.5341\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 5s 276ms/step - loss: 3.6437 - val_loss: 3.5325\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 5s 280ms/step - loss: 3.6422 - val_loss: 3.5310\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 5s 272ms/step - loss: 3.6407 - val_loss: 3.5297\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 5s 275ms/step - loss: 3.6394 - val_loss: 3.5284\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 5s 272ms/step - loss: 3.6382 - val_loss: 3.5272\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 5s 273ms/step - loss: 3.6370 - val_loss: 3.5260\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 5s 274ms/step - loss: 3.6359 - val_loss: 3.5250\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 3.6348 - val_loss: 3.5240\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 3.6339 - val_loss: 3.5230\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6329 - val_loss: 3.5221\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 5s 271ms/step - loss: 3.6321 - val_loss: 3.5212\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 3.6312 - val_loss: 3.5204\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6305 - val_loss: 3.5197\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 5s 275ms/step - loss: 3.6297 - val_loss: 3.5190\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 5s 272ms/step - loss: 3.6290 - val_loss: 3.5183\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 3.6283 - val_loss: 3.5176\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 5s 267ms/step - loss: 3.6277 - val_loss: 3.5170\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6271 - val_loss: 3.5165\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 6s 322ms/step - loss: 3.6265 - val_loss: 3.5159\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 3.6260 - val_loss: 3.5154\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 3.6255 - val_loss: 3.5149\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 3.6250 - val_loss: 3.5144\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 3.6245 - val_loss: 3.5139\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6241 - val_loss: 3.5135\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 3.6236 - val_loss: 3.5131\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 4s 247ms/step - loss: 3.6232 - val_loss: 3.5127\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 3.6228 - val_loss: 3.5123\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 5s 275ms/step - loss: 3.6225 - val_loss: 3.5119\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6221 - val_loss: 3.5116\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 3.6217 - val_loss: 3.5112\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 5s 264ms/step - loss: 3.6214 - val_loss: 3.5109\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 5s 276ms/step - loss: 3.6211 - val_loss: 3.5106\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 3.6208 - val_loss: 3.5103\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 5s 259ms/step - loss: 3.6205 - val_loss: 3.5101\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 5s 259ms/step - loss: 3.6202 - val_loss: 3.5098\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 3.6200 - val_loss: 3.5095\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 3.6197 - val_loss: 3.5093\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 3.6194 - val_loss: 3.5090\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 5s 251ms/step - loss: 3.6192 - val_loss: 3.5087\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 3.6190 - val_loss: 3.5086\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 5s 254ms/step - loss: 3.6187 - val_loss: 3.5083\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 5s 263ms/step - loss: 3.6185 - val_loss: 3.5081\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 3.6183 - val_loss: 3.5079\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 3.6181 - val_loss: 3.5077\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 5s 263ms/step - loss: 3.6179 - val_loss: 3.5076\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 5s 274ms/step - loss: 3.6177 - val_loss: 3.5074\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 5s 278ms/step - loss: 3.6176 - val_loss: 3.5072\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 5s 295ms/step - loss: 3.6174 - val_loss: 3.5070\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 3.6172 - val_loss: 3.5068\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 3.6171 - val_loss: 3.5067\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 3.6169 - val_loss: 3.5065\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 5s 260ms/step - loss: 3.6167 - val_loss: 3.5064\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 5s 276ms/step - loss: 3.6166 - val_loss: 3.5063\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 3.6164 - val_loss: 3.5061\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 5s 259ms/step - loss: 3.6163 - val_loss: 3.5060\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.6162 - val_loss: 3.5058\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 5s 271ms/step - loss: 3.6160 - val_loss: 3.5057\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.6159 - val_loss: 3.5056\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 3.6158 - val_loss: 3.5055\n"
     ]
    }
   ],
   "source": [
    "history_1 = point_net_1.fit(x=X_train, y=Y_train,\n",
    "                           epochs=100,\n",
    "                           batch_size=100,\n",
    "                           validation_data=(X_val, Y_val),\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7e80dd3d-a455-4d01-80cf-f7fef84a609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(history_1.history['val_loss'], label=\"Validation\")\n",
    "plt.plot(history_1.history['loss'], label=\"Training\")\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "# plt.ylim(.001,10)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xlim(0,len(history_1.history['loss'])-1)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(loc='upper right', ncol=1, prop={\"family\":'DejaVu Sans', 'size':'16'})\n",
    "# plt.text(1000, 1.5, 'LR=1e-3', fontsize=13)\n",
    "# plt.text(1000, 1, 'Batch: 3000', fontsize=13)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('Regression_Plots/July/STSC_lossCurves_3000batch_LR1e-3_2021-07-26.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a070c0-2929-4017-934d-194bd6656b85",
   "metadata": {},
   "source": [
    "### Producing plots of predictions versus truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28fc42ba-ae75-4d3f-ae94-a0bf471c16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat_test.cardinality())\n",
    "\n",
    "# dat_test.get_single_element()\n",
    "# # print(tf.rank(dat_test))\n",
    "# print('Batch size: '+str(int(batch_size)))\n",
    "# keras.backend.int_shape(dat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "87532635-c5b6-4a6a-a4a9-24ccd72000da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = point_net_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd416c24-0d4c-49c7-98fa-090f2e925528",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 1078, 3)\n",
      "[[6.19573693e-04 3.54599979e-05 6.24664608e-06]\n",
      " [6.08299219e-04 5.98753395e-05 5.38312042e-06]\n",
      " [6.02630083e-04 5.75550475e-05 5.50933737e-06]\n",
      " [5.56852727e-04 5.99361847e-05 6.26176552e-06]\n",
      " [5.44310024e-04 6.06031026e-05 6.52402287e-06]\n",
      " [5.45506773e-04 6.80253652e-05 6.39442078e-06]\n",
      " [5.38717548e-04 5.92388351e-05 6.65066182e-06]\n",
      " [5.26384101e-04 6.15726603e-05 6.94262781e-06]\n",
      " [5.30141755e-04 6.49437716e-05 6.81588108e-06]\n",
      " [5.19144465e-04 7.85828161e-05 6.99270595e-06]\n",
      " [5.51715319e-04 7.61550837e-05 6.28900489e-06]\n",
      " [5.27646625e-04 6.58566569e-05 6.80129097e-06]\n",
      " [5.51671430e-04 7.57705347e-05 6.28133512e-06]\n",
      " [5.30795078e-04 8.38611159e-05 6.74603325e-06]\n",
      " [5.32164238e-04 7.34763598e-05 6.69567726e-06]\n",
      " [4.97064204e-04 8.08675904e-05 7.61479623e-06]\n",
      " [5.84972848e-04 9.95536975e-05 5.73116813e-06]\n",
      " [5.26546384e-04 1.74861605e-04 8.60070395e-06]\n",
      " [4.94066044e-04 9.18790320e-05 7.69766757e-06]\n",
      " [5.30276506e-04 1.13066257e-04 7.14850876e-06]\n",
      " [5.11041842e-04 1.03445484e-04 7.53298855e-06]\n",
      " [4.99531627e-04 1.31103603e-04 8.36637628e-06]\n",
      " [4.75735811e-04 9.16680801e-05 8.35062565e-06]\n",
      " [4.56581358e-04 1.00457364e-04 9.12116047e-06]\n",
      " [4.78705391e-04 1.10821689e-04 8.62235993e-06]\n",
      " [4.81386698e-04 9.83170103e-05 8.24995368e-06]\n",
      " [4.72848304e-04 9.83896971e-05 8.60212276e-06]\n",
      " [4.95550630e-04 1.14719238e-04 8.14940813e-06]\n",
      " [5.06327080e-04 1.06631975e-04 7.52691403e-06]\n",
      " [4.77759691e-04 1.18109085e-04 8.91570016e-06]\n",
      " [4.57350718e-04 1.18480129e-04 9.64185438e-06]\n",
      " [5.08878904e-04 1.31815759e-04 8.01650094e-06]\n",
      " [5.12248254e-04 1.32419344e-04 8.04375668e-06]\n",
      " [4.55972971e-04 1.25626117e-04 9.71846111e-06]\n",
      " [4.81948315e-04 1.32811532e-04 9.14373595e-06]\n",
      " [4.78917995e-04 1.34225658e-04 9.15578585e-06]\n",
      " [4.58458613e-04 1.28961372e-04 9.80963341e-06]\n",
      " [4.46706603e-04 1.34028829e-04 1.04812752e-05]\n",
      " [4.61319200e-04 1.35146140e-04 9.69669145e-06]\n",
      " [4.78099973e-04 1.42065459e-04 9.46024647e-06]\n",
      " [4.51860513e-04 1.37273571e-04 1.03473658e-05]\n",
      " [4.70050611e-04 1.47639876e-04 9.72092403e-06]\n",
      " [4.27708146e-04 1.25500723e-04 1.08231061e-05]\n",
      " [5.00296999e-04 1.54443798e-04 8.87217993e-06]\n",
      " [4.48671839e-04 1.34810893e-04 1.02792346e-05]\n",
      " [4.39663796e-04 1.34610280e-04 1.06806538e-05]\n",
      " [4.57538816e-04 1.46910650e-04 1.00408679e-05]\n",
      " [5.12651110e-04 1.65332705e-04 8.61185799e-06]\n",
      " [4.64845769e-04 1.43254612e-04 9.83517293e-06]\n",
      " [4.64726705e-04 1.58500625e-04 1.03334996e-05]\n",
      " [4.28527099e-04 1.38404634e-04 1.13322358e-05]\n",
      " [4.59511386e-04 1.51409593e-04 1.04174678e-05]\n",
      " [4.65335033e-04 1.61798744e-04 1.03660332e-05]\n",
      " [4.40184202e-04 1.57617120e-04 1.13497363e-05]\n",
      " [4.39049851e-04 1.54866124e-04 1.12521584e-05]\n",
      " [4.47045750e-04 1.62533528e-04 1.09818111e-05]\n",
      " [4.68445243e-04 1.74593821e-04 1.03546799e-05]\n",
      " [4.33966983e-04 1.50532767e-04 1.16419478e-05]\n",
      " [4.59670409e-04 1.67247170e-04 1.09338644e-05]\n",
      " [4.63287084e-04 1.76806978e-04 1.08461072e-05]\n",
      " [4.99937218e-04 1.98676818e-04 9.90437729e-06]\n",
      " [4.18872776e-04 1.70394938e-04 1.29985210e-05]\n",
      " [4.41064243e-04 1.78728267e-04 1.20081240e-05]\n",
      " [4.51513828e-04 1.78414135e-04 1.12827029e-05]\n",
      " [4.61719465e-04 1.91498330e-04 1.10667379e-05]\n",
      " [4.00326826e-04 1.63570789e-04 1.35877499e-05]\n",
      " [3.96204705e-04 1.69624662e-04 1.39631165e-05]\n",
      " [4.41465934e-04 2.01208182e-04 1.24101798e-05]\n",
      " [4.24183556e-04 1.94432461e-04 1.26020295e-05]\n",
      " [4.41746524e-04 2.02980402e-04 1.21476787e-05]\n",
      " [4.09923086e-04 2.02040697e-04 1.34339298e-05]\n",
      " [4.39718628e-04 2.21890208e-04 1.23279369e-05]\n",
      " [3.78580153e-04 2.06447832e-04 1.57024278e-05]\n",
      " [4.08105581e-04 2.26402204e-04 1.38177338e-05]\n",
      " [4.05782543e-04 2.27565615e-04 1.40601151e-05]\n",
      " [4.19889606e-04 2.32936611e-04 1.31776196e-05]\n",
      " [3.93284688e-04 2.15884487e-04 1.46272423e-05]\n",
      " [4.35811584e-04 2.47265183e-04 1.27231215e-05]\n",
      " [3.92706454e-04 2.39427623e-04 1.51790027e-05]\n",
      " [4.61507501e-04 2.78011168e-04 1.19126535e-05]\n",
      " [3.76284064e-04 2.25028678e-04 1.57757568e-05]\n",
      " [4.30373359e-04 2.59971916e-04 1.28187758e-05]\n",
      " [3.85861960e-04 2.43084854e-04 1.54120098e-05]\n",
      " [4.01760219e-04 2.34388950e-04 1.42091267e-05]\n",
      " [3.99357988e-04 2.45388830e-04 1.44116093e-05]\n",
      " [3.92610847e-04 2.35550862e-04 1.46569091e-05]\n",
      " [4.45911661e-04 2.71034922e-04 1.22473566e-05]\n",
      " [3.93494061e-04 2.25688331e-04 1.47995297e-05]\n",
      " [3.71660804e-04 2.29433033e-04 1.60753443e-05]\n",
      " [4.22100478e-04 2.60232046e-04 1.34298125e-05]\n",
      " [3.96767922e-04 2.41595655e-04 1.49029784e-05]\n",
      " [4.30209941e-04 2.75952567e-04 1.30697836e-05]\n",
      " [3.81681748e-04 2.45413714e-04 1.60035579e-05]\n",
      " [3.99982731e-04 2.51565769e-04 1.48831796e-05]\n",
      " [4.13366128e-04 2.79904372e-04 1.42577692e-05]\n",
      " [4.45473124e-04 3.00330343e-04 1.30472990e-05]\n",
      " [4.39762021e-04 2.80816923e-04 1.29763439e-05]\n",
      " [4.15519491e-04 2.63868773e-04 1.40143857e-05]\n",
      " [4.22853744e-04 2.73544400e-04 1.36203271e-05]\n",
      " [3.89073975e-04 2.54330138e-04 1.53209694e-05]\n",
      " [4.13072121e-04 2.52852740e-04 1.41486425e-05]\n",
      " [4.30124113e-04 2.66633753e-04 1.33175381e-05]\n",
      " [4.28480591e-04 2.68115487e-04 1.32833675e-05]\n",
      " [4.31665045e-04 2.70472839e-04 1.30135668e-05]\n",
      " [4.17966803e-04 2.70394143e-04 1.38436581e-05]\n",
      " [3.82486207e-04 2.52777798e-04 1.58823332e-05]\n",
      " [3.98891250e-04 2.56423285e-04 1.49556072e-05]\n",
      " [4.05851955e-04 2.71261786e-04 1.43554516e-05]\n",
      " [4.19410324e-04 2.85409653e-04 1.37735278e-05]\n",
      " [4.00289980e-04 2.62740359e-04 1.51292797e-05]\n",
      " [4.13800502e-04 2.81263259e-04 1.43115594e-05]\n",
      " [3.80981539e-04 2.56865460e-04 1.59697120e-05]\n",
      " [3.94127826e-04 2.70863937e-04 1.52143066e-05]\n",
      " [4.37642389e-04 2.92334502e-04 1.31361257e-05]\n",
      " [4.30801068e-04 2.97014660e-04 1.34813072e-05]\n",
      " [4.44358069e-04 3.22920503e-04 1.30466706e-05]\n",
      " [4.68003593e-04 3.55342403e-04 1.19857550e-05]\n",
      " [3.91088834e-04 2.99113308e-04 1.56894948e-05]\n",
      " [4.52245818e-04 3.46077344e-04 1.27379744e-05]\n",
      " [4.67470993e-04 3.67195200e-04 1.17350028e-05]\n",
      " [4.43148718e-04 3.42271320e-04 1.28763804e-05]\n",
      " [4.21038159e-04 3.39267950e-04 1.43963771e-05]\n",
      " [4.55576635e-04 3.65626882e-04 1.26726418e-05]\n",
      " [4.09110420e-04 3.40277154e-04 1.46213006e-05]\n",
      " [3.87286214e-04 3.11832031e-04 1.62202687e-05]\n",
      " [4.46321588e-04 3.56502336e-04 1.31127699e-05]\n",
      " [4.01920144e-04 3.37635982e-04 1.51466256e-05]\n",
      " [4.57735208e-04 3.92265123e-04 1.23058771e-05]\n",
      " [4.50959022e-04 3.80023499e-04 1.28061056e-05]\n",
      " [4.88707796e-04 4.14050592e-04 1.14119166e-05]\n",
      " [4.11112269e-04 3.72932613e-04 1.44707546e-05]\n",
      " [3.75981675e-04 3.35236517e-04 1.64642188e-05]\n",
      " [4.01088415e-04 3.62242368e-04 1.48145546e-05]\n",
      " [3.90322151e-04 3.61703336e-04 1.53979490e-05]\n",
      " [4.30752116e-04 4.03457991e-04 1.28234951e-05]\n",
      " [4.06541512e-04 3.87924490e-04 1.42536564e-05]\n",
      " [4.43262456e-04 4.10382374e-04 1.23712252e-05]\n",
      " [3.75886302e-04 3.57360928e-04 1.59100437e-05]\n",
      " [3.85794759e-04 4.06382314e-04 1.41995970e-05]\n",
      " [3.54298449e-04 3.65656771e-04 1.66875125e-05]\n",
      " [3.44401225e-04 3.85953463e-04 1.58432431e-05]\n",
      " [3.78781901e-04 3.94416711e-04 1.50613678e-05]\n",
      " [3.48747737e-04 3.75086354e-04 1.61220851e-05]\n",
      " [3.36971774e-04 3.65854532e-04 1.67567723e-05]\n",
      " [3.41221021e-04 3.84277548e-04 1.57487066e-05]\n",
      " [3.87471984e-04 4.38652554e-04 1.31227207e-05]\n",
      " [3.19942978e-04 3.59233236e-04 1.73020144e-05]\n",
      " [3.15412530e-04 3.61163751e-04 1.72932560e-05]\n",
      " [3.61522427e-04 4.19514399e-04 1.39459826e-05]\n",
      " [3.58384626e-04 4.19642514e-04 1.43620937e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(preds_1))\n",
    "print(preds_1[0,:150,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02955d-348f-4217-b8cc-723280365ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
