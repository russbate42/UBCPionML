2022-02-12 21:36:07.557178: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0
2022-02-12 21:36:07.557936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9672 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:89:00.0, compute capability: 7.5
2022-02-12 21:41:13.097663: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 23327345160 exceeds 10% of free system memory.
2022-02-12 21:41:36.333327: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:265] gpu_async_0 cuMemAllocAsync failed to allocate 23327345160 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
 Reported by CUDA: Free memory/Total memory: 11224547328/11554717696
2022-02-12 21:41:36.333525: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:270] Stats: Limit:                     10142416896
InUse:                          228404
MaxInUse:                       307568
NumAllocs:                          49
MaxAllocSize:                    51200
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2022-02-12 21:41:36.333616: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;
2022-02-12 21:41:36.333636: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 12
2022-02-12 21:41:36.333648: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 2
2022-02-12 21:41:36.333658: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 400, 6
2022-02-12 21:41:36.333668: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 512, 1
2022-02-12 21:41:36.333678: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1
2022-02-12 21:41:36.333687: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2000, 1
2022-02-12 21:41:36.333698: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 40000, 3
2022-02-12 21:41:36.333708: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 51200, 2
2022-02-12 21:41:36.333744: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:90] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 33554432
2022-02-12 21:41:36.333756: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:92] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 228404
2022-02-12 21:41:36.333765: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:93] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 33554432
2022-02-12 21:41:36.333775: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:94] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 307568

starting training with hard coded values..
Batch size: 2800
Learning rate: 0.001
Epochs: 1500
Model: PFN_base
GPU: 5
Training on full dataset... [?] events.

Loading data..
time to load data: 0.0051 (s)

X size: (1534290, 1086, 5)

train -- val -- test
1074003 -- 230144 -- 230143

time to split:   0.00 (m)

Loading models..
Model: "PFN_base"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input (InputLayer)              [(None, 1086, 5)]    0                                            
__________________________________________________________________________________________________
t_dist_0 (TimeDistributed)      (None, 1086, 100)    600         input[0][0]                      
__________________________________________________________________________________________________
activation_0 (Activation)       (None, 1086, 100)    0           t_dist_0[0][0]                   
__________________________________________________________________________________________________
t_dist_1 (TimeDistributed)      (None, 1086, 100)    10100       activation_0[0][0]               
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 1086, 100)    0           t_dist_1[0][0]                   
__________________________________________________________________________________________________
t_dist_2 (TimeDistributed)      (None, 1086, 128)    12928       activation_1[0][0]               
__________________________________________________________________________________________________
mask (Lambda)                   (None, 1086)         0           input[0][0]                      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1086, 128)    0           t_dist_2[0][0]                   
__________________________________________________________________________________________________
sum (Dot)                       (None, 128)          0           mask[0][0]                       
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 100)          0           dense_0[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 100)          10100       activation_3[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 100)          10100       activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 100)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 1)            101         activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 1)            0           output[0][0]                     
==================================================================================================
Total params: 56,829
Trainable params: 56,829
Non-trainable params: 0
__________________________________________________________________________________________________

Training model..

Traceback (most recent call last):
  File "train_pflow.py", line 176, in <module>
    history = model.fit(X_train,
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1134, in fit
    data_handler = data_adapter.get_data_handler(
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py", line 1383, in get_data_handler
    return DataHandler(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py", line 1138, in __init__
    self._adapter = adapter_cls(
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py", line 230, in __init__
    x, y, sample_weights = _process_tensorlike((x, y, sample_weights))
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py", line 1031, in _process_tensorlike
    inputs = tf.nest.map_structure(_convert_numpy_and_scipy, inputs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py", line 869, in map_structure
    structure[0], [func(*x) for x in entries],
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py", line 869, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py", line 1026, in _convert_numpy_and_scipy
    return tf.convert_to_tensor(x, dtype=dtype)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py", line 1430, in convert_to_tensor_v2_with_dispatch
    return convert_to_tensor_v2(
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py", line 1436, in convert_to_tensor_v2
    return convert_to_tensor(
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py", line 271, in constant
    return _constant_impl(value, dtype, shape, name, verify_shape=False,
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py", line 106, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.
